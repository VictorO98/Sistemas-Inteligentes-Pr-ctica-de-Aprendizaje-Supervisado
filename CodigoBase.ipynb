{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Sistemas Inteligentes </h1>\n",
    "<h1> Práctica de Aprendizaje Supervisado </h1>\n",
    "\n",
    "En esta práctica vamos a ver cómo se hace el entrenamiento de un método de aprendizaje supervisado en la librería scikit learn para python.\n",
    "\n",
    "Las tareas a realizar son:\n",
    "-  Cargar el conjunto de datos\n",
    "-  Preparar los conjuntos de entrenamiento y prueba\n",
    "-  Probar el modelo construido con un conjunto de prueba\n",
    "-  Aplicar métricas de desempeño para evaluar el desempeño del modelo\n",
    "\n",
    "Mayo de 2020 <br/>\n",
    "Autor: G. Alvarez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentación\n",
    "# X_Train : los datos con los que se va entrenar el modelo\n",
    "# X_test : son las respuestas de los datos con los cuales se va entrenar el model\n",
    "# y_train : los datos con lo que se ve testiar el model\n",
    "# y_test : las respuestas de los datos con los que se va testiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAR VARIABLES\n",
    "PUNTO1 = [0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de librerías y lectura del archivo que contiene los datos\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "data = pd.read_csv(url, header=None, na_values=\" ?\")\n",
    "\n",
    "#Ponemos nombre a las columnas (Esta información se toma del archivo original adult.names que está en el \n",
    "#repositorio junto con el archivo de datos)\n",
    "data.columns = ['Age', 'Workclass', 'Fnlwgt', 'Education', 'Education-num', 'Marital-status', 'Occupation',\n",
    "              'Relationship', 'Race', 'Sex', 'Capital-gain', 'Capital-loss', 'Hpw', 'Country', 'C']\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cuál es el número de registros?\n",
    "#Cuál es el número de atributos?\n",
    "\n",
    "shape = data.shape\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <=50K    24720\n",
      " >50K      7841\n",
      "Name: C, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Cuantos registros hay por cada clase? es decir, por cada valor del atributo de salida?\n",
    "\n",
    "print(data['C'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las actividades siguientes corresponden al preprocesamiento de los datos para poderlos utilizar en el entrenamiento. Esta es una etapa importante y necesaria, a continuación se muestra la forma cómo se hace, aunque el propósito de la práctica tiene que ver más con la realización del entrenamiento, por lo que no se explicará en detalle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32534, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15674, 15)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminar los registros que tienen más de 2 datos faltantes\n",
    "data = data.dropna(axis = 0, thresh = 13)\n",
    "print(data.shape)\n",
    "\n",
    "# Reemplazar los datos faltantes por la moda en los atributos Workclass, Occupation, Country\n",
    "data.Workclass.fillna(data.Workclass.mode()[0], inplace=True)\n",
    "data.Occupation.fillna(data.Workclass.mode()[0], inplace=True)\n",
    "data.Country.fillna(data.Workclass.mode()[0], inplace=True)\n",
    "\n",
    "# Convertir los atributos categóricos a escala numérica\n",
    "# Esto modifica los valores de todas las columnas, incluso las numéricas\n",
    "le = preprocessing.LabelEncoder()\n",
    "data = data.apply(le.fit_transform) \n",
    "\n",
    "# Balanceo entre clases\n",
    "g = data.groupby('C')\n",
    "dataBal = pd.DataFrame(g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True)))\n",
    "dataBal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (9404, 14)\n",
      "X_test: (6270, 14)\n",
      "y_train: (9404,)\n",
      "y_test: (6270,)\n"
     ]
    }
   ],
   "source": [
    "# Separacion de los datos en conjuntos de entrenamiento, validacion y prueba. Se trabaja sobre el conjunto balanceado\n",
    "# Cuando finalice la depuración recordar quitar el parámetro random_state.\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataBal.drop(['C'],axis=1), dataBal['C'], test_size=0.4, random_state=42)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimación de parámetros\n",
    "# En este código se ilustra el uso de la función que trae la librería sklearn para estimar paramentros,\n",
    "# la cual no necesita la extracción explícita del conjunto de validación pues hace la estimación usando\n",
    "# validación cruzada sobre el conjunto de entrenamiento.\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def metricasAgente(sizeTest):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataBal.drop(['C'],axis=1), dataBal['C']\n",
    "                                                        , test_size=sizeTest)\n",
    "\n",
    "    # print(\"X_train:\", X_train.shape)\n",
    "    # print(\"X_test:\", X_test.shape)\n",
    "    # print(\"y_train:\", y_train.shape)\n",
    "    # print(\"y_test:\", y_test.shape)\n",
    "\n",
    "    # Se crea el clasificador base\n",
    "    clf = SVC()\n",
    "\n",
    "    # Se definen los valores a explorar para cada parametro a estimar\n",
    "    parameter_space = [{'kernel': ['rbf', 'sigmoid'], \n",
    "    #parameter_space = [{'kernel': ['rbf'], \n",
    "                         'gamma': [1e-3, 1e-4],\n",
    "                         'C': [1, 10, 100]\n",
    "                        }]\n",
    "\n",
    "    # Se realiza la estimacion de parametros, en clf queda el modelo construido con los mejores\n",
    "    # parametros encontrados y reentrenado con el conjunto de datos completo (refit)\n",
    "    clf = GridSearchCV(clf, parameter_space, n_jobs=-1, cv=3, refit=True)\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    # Se identifican los parametros que producen el mejor modelo\n",
    "    print(\"Mejores parametros:\")\n",
    "    print(clf.best_params_)\n",
    "\n",
    "    # Se hace la prediccion sobre los datos de prueba\n",
    "    pred = clf.predict(X_test)\n",
    "\n",
    "    # Se calculan metricas a partir de los datos de prueba\n",
    "    mat = confusion_matrix(y_test, pred)\n",
    "    print(mat)\n",
    "    \n",
    "    # Metricas\n",
    "    pre = precision_score(y_test,pred)\n",
    "    rec = recall_score(y_test,pred)\n",
    "    f1Score = f1_score(y_test,pred)\n",
    "    \n",
    "    # Calculo en el vector de las metricas acumulando\n",
    "    PUNTO1[0] = PUNTO1[0] + pre       # Presición\n",
    "    PUNTO1[1] = PUNTO1[1] + rec       # Recall\n",
    "    PUNTO1[2] = PUNTO1[2] + f1Score   # F1 Score\n",
    "    \n",
    "    # print(\"Precision: \", pre)\n",
    "    # print(\"Recall:    \", rec)\n",
    "    # print(\"F1score:   \",f1Score)\n",
    "    print(\"Reporte\",classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/-------------------------------------/\n",
      "Iteracion:  0\n",
      "...\n",
      "Mejores parametros:\n",
      "{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "[[1652  697]\n",
      " [ 676 1678]]\n",
      "Reporte               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.71      2349\n",
      "           1       0.71      0.71      0.71      2354\n",
      "\n",
      "    accuracy                           0.71      4703\n",
      "   macro avg       0.71      0.71      0.71      4703\n",
      "weighted avg       0.71      0.71      0.71      4703\n",
      "\n",
      "/-------------------------------------/\n",
      "Iteracion:  1\n",
      "...\n",
      "Mejores parametros:\n",
      "{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "[[1686  677]\n",
      " [ 705 1635]]\n",
      "Reporte               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71      2363\n",
      "           1       0.71      0.70      0.70      2340\n",
      "\n",
      "    accuracy                           0.71      4703\n",
      "   macro avg       0.71      0.71      0.71      4703\n",
      "weighted avg       0.71      0.71      0.71      4703\n",
      "\n",
      "/-------------------------------------/\n",
      "Iteracion:  2\n",
      "...\n",
      "Mejores parametros:\n",
      "{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "[[1664  697]\n",
      " [ 695 1647]]\n",
      "Reporte               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.71      2361\n",
      "           1       0.70      0.70      0.70      2342\n",
      "\n",
      "    accuracy                           0.70      4703\n",
      "   macro avg       0.70      0.70      0.70      4703\n",
      "weighted avg       0.70      0.70      0.70      4703\n",
      "\n",
      "/-------------------------------------/\n",
      "Iteracion:  3\n",
      "...\n",
      "Mejores parametros:\n",
      "{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "[[1637  670]\n",
      " [ 716 1680]]\n",
      "Reporte               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.71      0.70      2307\n",
      "           1       0.71      0.70      0.71      2396\n",
      "\n",
      "    accuracy                           0.71      4703\n",
      "   macro avg       0.71      0.71      0.71      4703\n",
      "weighted avg       0.71      0.71      0.71      4703\n",
      "\n",
      "/-------------------------------------/\n",
      "Iteracion:  4\n",
      "...\n",
      "Mejores parametros:\n",
      "{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "[[1691  678]\n",
      " [ 685 1649]]\n",
      "Reporte               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71      2369\n",
      "           1       0.71      0.71      0.71      2334\n",
      "\n",
      "    accuracy                           0.71      4703\n",
      "   macro avg       0.71      0.71      0.71      4703\n",
      "weighted avg       0.71      0.71      0.71      4703\n",
      "\n",
      "/--------PROMEDIOS----------/\n",
      "Resultados de promedios\n",
      "Arreglo de metricas promediadas\n",
      "Promedio Recall después de 5 iteraciones: 0.8474791416083873\n",
      "Promedio Presición después de 5 iteraciones: 0.8465695553222414\n",
      "Promedio F1 después de 5 iteraciones: 0.8469824054207449\n"
     ]
    }
   ],
   "source": [
    "# Punto 1\n",
    "def punto1(N, sizeTest):\n",
    "    for i in range(N): # Llamado del agente para revisar las metricas\n",
    "        print(\"/-------------------------------------/\")\n",
    "        print(\"Iteracion: \", i)\n",
    "        print(\"...\")\n",
    "        metricasAgente(sizeTest)\n",
    "        \n",
    "    # Promedios de las metricas\n",
    "    PUNTO1[0] = PUNTO1[0] / N     # Presición\n",
    "    PUNTO1[1] = PUNTO1[1] / N     # Recall\n",
    "    PUNTO1[2] = PUNTO1[2] / N     # F1 Score\n",
    "    \n",
    "    print(\"/--------PROMEDIOS----------/\")\n",
    "    print(\"Resultados de promedios\")\n",
    "    print(\"Promedio Recall después de {0} iteraciones: {1}\".format(N,PUNTO1[0]))\n",
    "    print(\"Promedio Presición después de {0} iteraciones: {1}\".format(N,PUNTO1[1]))\n",
    "    print(\"Promedio F1 después de {0} iteraciones: {1}\".format(N,PUNTO1[2]))\n",
    "    \n",
    "punto1(5, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Punto 2\n",
    "# Estimación de parámetros\n",
    "# En este código se ilustra el uso de la función que trae la librería sklearn para estimar paramentros,\n",
    "# la cual no necesita la extracción explícita del conjunto de validación pues hace la estimación usando\n",
    "# validación cruzada sobre el conjunto de entrenamiento.\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def ArbolDesicion(sizeTest, profundidadArbol):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataBal.drop(['C'],axis=1), dataBal['C']\n",
    "                                                        , test_size=sizeTest)\n",
    "\n",
    "    # print(\"X_train:\", X_train.shape)\n",
    "    # print(\"X_test:\", X_test.shape)\n",
    "    # print(\"y_train:\", y_train.shape)\n",
    "    # print(\"y_test:\", y_test.shape)\n",
    "\n",
    "    # Clasificador de arbol de desiciones\n",
    "    arbol = DecisionTreeClassifier()\n",
    "    \n",
    "    # Entrenamiento del modelo\n",
    "    arbol.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculo de score en el modelo de test\n",
    "    arbol.score(X_test, y_test)\n",
    "    \n",
    "    # Calculo de score en el modelo de entrenamiento\n",
    "    arbol.score(X_train, y_train)\n",
    "    \n",
    "    print(arbol.score(X_test, y_test))\n",
    "    print(arbol.score(X_train, y_train))\n",
    "    \n",
    "    # Crear archivo .dot para mostrar el arbol\n",
    "    \n",
    "    # Re Ajuste del arbol con el número de profundidad máximo\n",
    "    arbol = DecisionTreeClassifier(max_depth=profundidadArbol)\n",
    "    \n",
    "    # Entrenamiento del modelo con Re Ajuste\n",
    "    arbol.fit(X_train, y_train)\n",
    "    \n",
    "     # Calculo de score en el modelo de test con Re Ajuste\n",
    "    arbol.score(X_test, y_test)\n",
    "    \n",
    "    # Calculo de score en el modelo de entrenamiento con Re Ajuste\n",
    "    arbol.score(X_train, y_train)\n",
    "    \n",
    "    print(arbol.score(X_test, y_test))\n",
    "    print(arbol.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7720893141945774\n",
      "1.0\n",
      "0.7751196172248804\n",
      "0.773713313483624\n"
     ]
    }
   ],
   "source": [
    "# Punto 2 Arbol\n",
    "\n",
    "def Punto2Arbol(sizeTest, profundidadArbol):\n",
    "    ArbolDesicion(sizeTest, profundidadArbol)\n",
    "Punto2Arbol(0.4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Punto 2\n",
    "# Estimación de parámetros\n",
    "# En este código se ilustra el uso de la función que trae la librería sklearn para estimar paramentros,\n",
    "# la cual no necesita la extracción explícita del conjunto de validación pues hace la estimación usando\n",
    "# validación cruzada sobre el conjunto de entrenamiento.\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def RegresionLogistica(sizeTest):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataBal.drop(['C'],axis=1), dataBal['C']\n",
    "                                                        , test_size=sizeTest)\n",
    "\n",
    "    # print(\"X_train:\", X_train.shape)\n",
    "    # print(\"X_test:\", X_test.shape)\n",
    "    # print(\"y_train:\", y_train.shape)\n",
    "    # print(\"y_test:\", y_test.shape)\n",
    "    \n",
    "    # Se escalan todos los datos\n",
    "    escalar = StandardScaler()\n",
    "    X_train = escalar.fit_transform(X_train)\n",
    "    X_test = escalar.transform(X_test)\n",
    "    \n",
    "    # Entrenamiento de los modelos\n",
    "    algoritmo = LogisticRegression()\n",
    "    \n",
    "    algoritmo.fit(X_train,y_train)\n",
    "    \n",
    "    # Se realiza una predicción\n",
    "    y_pred = algoritmo.predict(X_test)\n",
    "    \n",
    "    # Matriz de confusión \n",
    "    mat = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Matriz de confusión\")\n",
    "    print(mat)\n",
    "    \n",
    "    # Metricas\n",
    "    pre = precision_score(y_test,y_pred)\n",
    "    rec = recall_score(y_test,y_pred)\n",
    "    f1Score = f1_score(y_test,y_pred)\n",
    "    \n",
    "    print(\"Precision: \", pre)\n",
    "    print(\"Recall:    \", rec)\n",
    "    print(\"F1score:   \",f1Score)\n",
    "    print(\"Reporte\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión\n",
      "[[2395  741]\n",
      " [ 697 2437]]\n",
      "Precision:  0.7668344870988043\n",
      "Recall:     0.7776005105296745\n",
      "F1score:    0.7721799746514575\n",
      "Reporte               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77      3136\n",
      "           1       0.77      0.78      0.77      3134\n",
      "\n",
      "    accuracy                           0.77      6270\n",
      "   macro avg       0.77      0.77      0.77      6270\n",
      "weighted avg       0.77      0.77      0.77      6270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Punto 2 Regresión Logistica \n",
    "\n",
    "def Punto2Regresion():\n",
    "    RegresionLogistica(0.4)\n",
    "Punto2Regresion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Actividades a realizar a partir de este script básico: </h1>\n",
    "1.  Implementar el método holdout para obtener unas métricas de desempeño más confiables. Hacer 5 iteraciones  de las etapas de: partición de los datos - entrenamiento - prueba - calculo de metricas. No olvidar liberar la semilla del generador de números aleatorios.\n",
    "<br></br>\n",
    "2.  Adicionar dos métodos para poder comparar su desempeño, los métodos a adicionar son: árbol de decisiones y clasificacador por regresión logística.\n",
    "<br></br>\n",
    "3.  Mostrar los resultados comparativos gráficamente, incluyendo la visualización de las curvas ROC por cada método y el valor del área bajo la curva."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
