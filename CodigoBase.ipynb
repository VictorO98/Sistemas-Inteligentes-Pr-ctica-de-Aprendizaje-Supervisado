{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Sistemas Inteligentes </h1>\n",
    "<h1> Práctica de Aprendizaje Supervisado </h1>\n",
    "\n",
    "En esta práctica vamos a ver cómo se hace el entrenamiento de un método de aprendizaje supervisado en la librería scikit learn para python.\n",
    "\n",
    "Las tareas a realizar son:\n",
    "-  Cargar el conjunto de datos\n",
    "-  Preparar los conjuntos de entrenamiento y prueba\n",
    "-  Probar el modelo construido con un conjunto de prueba\n",
    "-  Aplicar métricas de desempeño para evaluar el desempeño del modelo\n",
    "\n",
    "Mayo de 2020 <br/>\n",
    "Autor: G. Alvarez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentación\n",
    "# X_Train : los datos con los que se va entrenar el modelo\n",
    "# y_train : Las respuestas de ese conjunto de datos (X_Train)\n",
    "# X_test : son un conjunto de datos diferente para probar el modelo\n",
    "# y_test : es la respuesta de ese conjunto de datos diferente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAR VARIABLES\n",
    "SVM = [0,0,0]\n",
    "ARBOL = [0,0,0]\n",
    "REGRESION = [0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de librerías y lectura del archivo que contiene los datos\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "data = pd.read_csv(url, header=None, na_values=\" ?\")\n",
    "\n",
    "#Ponemos nombre a las columnas (Esta información se toma del archivo original adult.names que está en el \n",
    "#repositorio junto con el archivo de datos)\n",
    "data.columns = ['Age', 'Workclass', 'Fnlwgt', 'Education', 'Education-num', 'Marital-status', 'Occupation',\n",
    "              'Relationship', 'Race', 'Sex', 'Capital-gain', 'Capital-loss', 'Hpw', 'Country', 'C']\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cuál es el número de registros?\n",
    "#Cuál es el número de atributos?\n",
    "\n",
    "shape = data.shape\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <=50K    24720\n",
      " >50K      7841\n",
      "Name: C, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Cuantos registros hay por cada clase? es decir, por cada valor del atributo de salida?\n",
    "\n",
    "print(data['C'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las actividades siguientes corresponden al preprocesamiento de los datos para poderlos utilizar en el entrenamiento. Esta es una etapa importante y necesaria, a continuación se muestra la forma cómo se hace, aunque el propósito de la práctica tiene que ver más con la realización del entrenamiento, por lo que no se explicará en detalle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32534, 15)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15674, 15)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminar los registros que tienen más de 2 datos faltantes\n",
    "data = data.dropna(axis = 0, thresh = 13)\n",
    "print(data.shape)\n",
    "\n",
    "# Reemplazar los datos faltantes por la moda en los atributos Workclass, Occupation, Country\n",
    "data.Workclass.fillna(data.Workclass.mode()[0], inplace=True)\n",
    "data.Occupation.fillna(data.Workclass.mode()[0], inplace=True)\n",
    "data.Country.fillna(data.Workclass.mode()[0], inplace=True)\n",
    "\n",
    "# Convertir los atributos categóricos a escala numérica\n",
    "# Esto modifica los valores de todas las columnas, incluso las numéricas\n",
    "le = preprocessing.LabelEncoder()\n",
    "data = data.apply(le.fit_transform) \n",
    "\n",
    "# Balanceo entre clases\n",
    "g = data.groupby('C')\n",
    "dataBal = pd.DataFrame(g.apply(lambda x: x.sample(g.size().min()).reset_index(drop=True)))\n",
    "dataBal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (9404, 14)\n",
      "X_test: (6270, 14)\n",
      "y_train: (9404,)\n",
      "y_test: (6270,)\n"
     ]
    }
   ],
   "source": [
    "# Separacion de los datos en conjuntos de entrenamiento, validacion y prueba. Se trabaja sobre el conjunto balanceado\n",
    "# Cuando finalice la depuración recordar quitar el parámetro random_state.\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataBal.drop(['C'],axis=1), dataBal['C'], test_size=0.4, random_state=42)\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimación de parámetros\n",
    "# En este código se ilustra el uso de la función que trae la librería sklearn para estimar paramentros,\n",
    "# la cual no necesita la extracción explícita del conjunto de validación pues hace la estimación usando\n",
    "# validación cruzada sobre el conjunto de entrenamiento.\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def SVM_FUN(sizeTest, X_train, X_test, y_train, y_test):\n",
    "    # Se crea el clasificador base\n",
    "    clf = SVC()\n",
    "\n",
    "    # Se definen los valores a explorar para cada parametro a estimar\n",
    "    parameter_space = [{'kernel': ['rbf', 'sigmoid'], \n",
    "    #parameter_space = [{'kernel': ['rbf'], \n",
    "                         'gamma': [1e-3, 1e-4],\n",
    "                         'C': [1, 10, 100]\n",
    "                        }]\n",
    "\n",
    "    # Se realiza la estimacion de parametros, en clf queda el modelo construido con los mejores\n",
    "    # parametros encontrados y reentrenado con el conjunto de datos completo (refit)\n",
    "    clf = GridSearchCV(clf, parameter_space, n_jobs=-1, cv=3, refit=True)\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    # Se identifican los parametros que producen el mejor modelo\n",
    "    print(\"Mejores parametros:\")\n",
    "    print(clf.best_params_)\n",
    "\n",
    "    # Se hace la prediccion sobre los datos de prueba\n",
    "    pred = clf.predict(X_test)\n",
    "\n",
    "    # Se calculan metricas a partir de los datos de prueba\n",
    "    mat = confusion_matrix(y_test, pred)\n",
    "    print(mat)\n",
    "    \n",
    "    # Metricas\n",
    "    pre = precision_score(y_test,pred)\n",
    "    rec = recall_score(y_test,pred)\n",
    "    f1Score = f1_score(y_test,pred)\n",
    "    \n",
    "    # Calculo en el vector de las metricas acumulando\n",
    "    SVM[0] = SVM[0] + pre       # Presición\n",
    "    SVM[1] = SVM[1] + rec       # Recall\n",
    "    SVM[2] = SVM[2] + f1Score   # F1 Score\n",
    "    \n",
    "    print(\"Precision: \", pre)\n",
    "    print(\"Recall:    \", rec)\n",
    "    print(\"F1score:   \",f1Score)\n",
    "    print(\"Reporte\",classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Punto 2\n",
    "# Estimación de parámetros\n",
    "# En este código se ilustra el uso de la función que trae la librería sklearn para estimar paramentros,\n",
    "# la cual no necesita la extracción explícita del conjunto de validación pues hace la estimación usando\n",
    "# validación cruzada sobre el conjunto de entrenamiento.\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def ArbolDesicion(sizeTest, profundidadArbol, X_train, X_test, y_train, y_test):\n",
    "    # Clasificador de arbol de desiciones\n",
    "    arbol = DecisionTreeClassifier()\n",
    "    \n",
    "    # Entrenamiento del modelo\n",
    "    arbol.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculo de score en el modelo de test\n",
    "    scoTest = arbol.score(X_test, y_test)\n",
    "    \n",
    "    # Calculo de score en el modelo de entrenamiento\n",
    "    scoTrain = arbol.score(X_train, y_train)\n",
    "    \n",
    "    # Predicción\n",
    "    pred = arbol.predict(X_test)\n",
    "    \n",
    "    # Metricas\n",
    "    pre = precision_score(y_test,pred)\n",
    "    rec = recall_score(y_test,pred)\n",
    "    f1Score = f1_score(y_test,pred)\n",
    "    \n",
    "    # Calculo en el vector de las metricas acumulando\n",
    "    ARBOL[0] = ARBOL[0] + pre       # Presición\n",
    "    ARBOL[1] = ARBOL[1] + rec       # Recall\n",
    "    ARBOL[2] = ARBOL[2] + f1Score   # F1 Score\n",
    "    \n",
    "    print(\"/----SIN RE AJUSTE----/\")\n",
    "    print(\"Score de test: \", scoTest)\n",
    "    print(\"Score de train: \", scoTrain)\n",
    "    print(\"Precision: \", pre)\n",
    "    print(\"Recall:    \", rec)\n",
    "    print(\"F1score:   \",f1Score)\n",
    "    '''\n",
    "    # Re Ajuste del arbol con el número de profundidad máximo\n",
    "    arbol = DecisionTreeClassifier(max_depth=profundidadArbol)\n",
    "    \n",
    "    # Entrenamiento del modelo con Re Ajuste\n",
    "    arbol.fit(X_train, y_train)\n",
    "    \n",
    "     # Calculo de score en el modelo de test con Re Ajuste\n",
    "    scoTest = arbol.score(X_test, y_test)\n",
    "    \n",
    "    # Calculo de score en el modelo de entrenamiento con Re Ajuste\n",
    "    scoTrain = arbol.score(X_train, y_train)\n",
    "    \n",
    "    # Metricas\n",
    "    pre = precision_score(y_test,pred)\n",
    "    rec = recall_score(y_test,pred)\n",
    "    f1Score = f1_score(y_test,pred)\n",
    "    \n",
    "    \n",
    "    print(\"/-----CON RE AJUSTE-----/\")\n",
    "    print(\"Score de test: \", scoTest)\n",
    "    print(\"Score de train: \", scoTrain)\n",
    "    print(\"Precision: \", pre)\n",
    "    print(\"Recall:    \", rec)\n",
    "    print(\"F1score:   \",f1Score)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Punto 2\n",
    "# Estimación de parámetros\n",
    "# En este código se ilustra el uso de la función que trae la librería sklearn para estimar paramentros,\n",
    "# la cual no necesita la extracción explícita del conjunto de validación pues hace la estimación usando\n",
    "# validación cruzada sobre el conjunto de entrenamiento.\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def RegresionLogistica(sizeTest,  X_train, X_test, y_train, y_test):\n",
    "    # Se escalan todos los datos\n",
    "    escalar = StandardScaler()\n",
    "    X_train = escalar.fit_transform(X_train)\n",
    "    X_test = escalar.transform(X_test)\n",
    "    \n",
    "    # Entrenamiento de los modelos\n",
    "    algoritmo = LogisticRegression()\n",
    "    \n",
    "    algoritmo.fit(X_train,y_train)\n",
    "    \n",
    "    # Se realiza una predicción\n",
    "    y_pred = algoritmo.predict(X_test)\n",
    "    \n",
    "    # Matriz de confusión \n",
    "    mat = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Matriz de confusión\")\n",
    "    print(mat)\n",
    "    \n",
    "    # Metricas\n",
    "    pre = precision_score(y_test,y_pred)\n",
    "    rec = recall_score(y_test,y_pred)\n",
    "    f1Score = f1_score(y_test,y_pred)\n",
    "    \n",
    "    # Calculo en el vector de las metricas acumulando\n",
    "    REGRESION[0] = REGRESION[0] + pre       # Presición\n",
    "    REGRESION[1] = REGRESION[1] + rec       # Recall\n",
    "    REGRESION[2] = REGRESION[2] + f1Score   # F1 Score\n",
    "    \n",
    "    print(\"Precision: \", pre)\n",
    "    print(\"Recall:    \", rec)\n",
    "    print(\"F1score:   \",f1Score)\n",
    "    print(\"Reporte\",classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/-------------------------------------/\n",
      "Iteracion:  1\n",
      "SVM\n",
      "...\n",
      "Mejores parametros:\n",
      "{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "[[2201  899]\n",
      " [ 993 2177]]\n",
      "Precision:  0.7077373211963589\n",
      "Recall:     0.6867507886435331\n",
      "F1score:    0.697086135126481\n",
      "Reporte               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70      3100\n",
      "           1       0.71      0.69      0.70      3170\n",
      "\n",
      "    accuracy                           0.70      6270\n",
      "   macro avg       0.70      0.70      0.70      6270\n",
      "weighted avg       0.70      0.70      0.70      6270\n",
      "\n",
      "ARBOL DE DECISIÓN\n",
      "...\n",
      "/----SIN RE AJUSTE----/\n",
      "Score de test:  0.7700159489633174\n",
      "Score de train:  1.0\n",
      "Precision:  0.7732447817836812\n",
      "Recall:     0.7712933753943217\n",
      "F1score:    0.7722678458622868\n",
      "REGRESIÓN LOGISTICA\n",
      "...\n",
      "Matriz de confusión\n",
      "[[2398  702]\n",
      " [ 765 2405]]\n",
      "Precision:  0.7740585774058577\n",
      "Recall:     0.7586750788643533\n",
      "F1score:    0.7662896288035684\n",
      "Reporte               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      3100\n",
      "           1       0.77      0.76      0.77      3170\n",
      "\n",
      "    accuracy                           0.77      6270\n",
      "   macro avg       0.77      0.77      0.77      6270\n",
      "weighted avg       0.77      0.77      0.77      6270\n",
      "\n",
      "/-------------------------------------/\n",
      "Iteracion:  2\n",
      "SVM\n",
      "...\n",
      "Mejores parametros:\n",
      "{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "[[2201  899]\n",
      " [ 993 2177]]\n",
      "Precision:  0.7077373211963589\n",
      "Recall:     0.6867507886435331\n",
      "F1score:    0.697086135126481\n",
      "Reporte               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70      3100\n",
      "           1       0.71      0.69      0.70      3170\n",
      "\n",
      "    accuracy                           0.70      6270\n",
      "   macro avg       0.70      0.70      0.70      6270\n",
      "weighted avg       0.70      0.70      0.70      6270\n",
      "\n",
      "ARBOL DE DECISIÓN\n",
      "...\n",
      "/----SIN RE AJUSTE----/\n",
      "Score de test:  0.769377990430622\n",
      "Score de train:  1.0\n",
      "Precision:  0.7733037412809132\n",
      "Recall:     0.7694006309148265\n",
      "F1score:    0.7713472485768501\n",
      "REGRESIÓN LOGISTICA\n",
      "...\n",
      "Matriz de confusión\n",
      "[[2398  702]\n",
      " [ 765 2405]]\n",
      "Precision:  0.7740585774058577\n",
      "Recall:     0.7586750788643533\n",
      "F1score:    0.7662896288035684\n",
      "Reporte               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      3100\n",
      "           1       0.77      0.76      0.77      3170\n",
      "\n",
      "    accuracy                           0.77      6270\n",
      "   macro avg       0.77      0.77      0.77      6270\n",
      "weighted avg       0.77      0.77      0.77      6270\n",
      "\n",
      "/-------------------------------------/\n",
      "Iteracion:  3\n",
      "SVM\n",
      "...\n",
      "Mejores parametros:\n",
      "{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "[[2201  899]\n",
      " [ 993 2177]]\n",
      "Precision:  0.7077373211963589\n",
      "Recall:     0.6867507886435331\n",
      "F1score:    0.697086135126481\n",
      "Reporte               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70      3100\n",
      "           1       0.71      0.69      0.70      3170\n",
      "\n",
      "    accuracy                           0.70      6270\n",
      "   macro avg       0.70      0.70      0.70      6270\n",
      "weighted avg       0.70      0.70      0.70      6270\n",
      "\n",
      "ARBOL DE DECISIÓN\n",
      "...\n",
      "/----SIN RE AJUSTE----/\n",
      "Score de test:  0.7722488038277512\n",
      "Score de train:  1.0\n",
      "Precision:  0.7756329113924051\n",
      "Recall:     0.773186119873817\n",
      "F1score:    0.7744075829383887\n",
      "REGRESIÓN LOGISTICA\n",
      "...\n",
      "Matriz de confusión\n",
      "[[2398  702]\n",
      " [ 765 2405]]\n",
      "Precision:  0.7740585774058577\n",
      "Recall:     0.7586750788643533\n",
      "F1score:    0.7662896288035684\n",
      "Reporte               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      3100\n",
      "           1       0.77      0.76      0.77      3170\n",
      "\n",
      "    accuracy                           0.77      6270\n",
      "   macro avg       0.77      0.77      0.77      6270\n",
      "weighted avg       0.77      0.77      0.77      6270\n",
      "\n",
      "/-------------------------------------/\n",
      "Iteracion:  4\n",
      "SVM\n",
      "...\n",
      "Mejores parametros:\n",
      "{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "[[2201  899]\n",
      " [ 993 2177]]\n",
      "Precision:  0.7077373211963589\n",
      "Recall:     0.6867507886435331\n",
      "F1score:    0.697086135126481\n",
      "Reporte               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70      3100\n",
      "           1       0.71      0.69      0.70      3170\n",
      "\n",
      "    accuracy                           0.70      6270\n",
      "   macro avg       0.70      0.70      0.70      6270\n",
      "weighted avg       0.70      0.70      0.70      6270\n",
      "\n",
      "ARBOL DE DECISIÓN\n",
      "...\n",
      "/----SIN RE AJUSTE----/\n",
      "Score de test:  0.7732057416267942\n",
      "Score de train:  1.0\n",
      "Precision:  0.778343949044586\n",
      "Recall:     0.7709779179810725\n",
      "F1score:    0.7746434231378764\n",
      "REGRESIÓN LOGISTICA\n",
      "...\n",
      "Matriz de confusión\n",
      "[[2398  702]\n",
      " [ 765 2405]]\n",
      "Precision:  0.7740585774058577\n",
      "Recall:     0.7586750788643533\n",
      "F1score:    0.7662896288035684\n",
      "Reporte               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      3100\n",
      "           1       0.77      0.76      0.77      3170\n",
      "\n",
      "    accuracy                           0.77      6270\n",
      "   macro avg       0.77      0.77      0.77      6270\n",
      "weighted avg       0.77      0.77      0.77      6270\n",
      "\n",
      "/-------------------------------------/\n",
      "Iteracion:  5\n",
      "SVM\n",
      "...\n",
      "Mejores parametros:\n",
      "{'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "[[2201  899]\n",
      " [ 993 2177]]\n",
      "Precision:  0.7077373211963589\n",
      "Recall:     0.6867507886435331\n",
      "F1score:    0.697086135126481\n",
      "Reporte               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70      3100\n",
      "           1       0.71      0.69      0.70      3170\n",
      "\n",
      "    accuracy                           0.70      6270\n",
      "   macro avg       0.70      0.70      0.70      6270\n",
      "weighted avg       0.70      0.70      0.70      6270\n",
      "\n",
      "ARBOL DE DECISIÓN\n",
      "...\n",
      "/----SIN RE AJUSTE----/\n",
      "Score de test:  0.7681020733652313\n",
      "Score de train:  1.0\n",
      "Precision:  0.7737715379706446\n",
      "Recall:     0.7649842271293376\n",
      "F1score:    0.7693527918781725\n",
      "REGRESIÓN LOGISTICA\n",
      "...\n",
      "Matriz de confusión\n",
      "[[2398  702]\n",
      " [ 765 2405]]\n",
      "Precision:  0.7740585774058577\n",
      "Recall:     0.7586750788643533\n",
      "F1score:    0.7662896288035684\n",
      "Reporte               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.77      3100\n",
      "           1       0.77      0.76      0.77      3170\n",
      "\n",
      "    accuracy                           0.77      6270\n",
      "   macro avg       0.77      0.77      0.77      6270\n",
      "weighted avg       0.77      0.77      0.77      6270\n",
      "\n",
      "/--------PROMEDIOS----------/\n",
      "* Resultados de promedios SVM\n",
      "    Promedio Recall después de 5 iteraciones: 0.876684357036096\n",
      "    Promedio Presición después de 5 iteraciones: 0.8513863649055237\n",
      "    Promedio F1 después de 5 iteraciones: 0.8638433818912061\n",
      "* Resultados de promedios ARBOLES DE DECISIÓN\n",
      "    Promedio Recall después de 5 iteraciones: 0.9564620448841359\n",
      "    Promedio Presición después de 5 iteraciones: 0.9496067579418286\n",
      "    Promedio F1 después de 5 iteraciones: 0.9530160516882488\n",
      "* Resultados de promedios REGRESIÓN LOGISTICA\n",
      "    Promedio Recall después de 5 iteraciones: 0.9584975287828474\n",
      "    Promedio Presición después de 5 iteraciones: 0.9412493910233799\n",
      "    Promedio F1 después de 5 iteraciones: 0.949783263591922\n"
     ]
    }
   ],
   "source": [
    "def main(N, sizeTest):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataBal.drop(['C'],axis=1), dataBal['C']\n",
    "                                                        , test_size=sizeTest)\n",
    "    for i in range(N): # Llamado del agente para revisar las metricas\n",
    "        print(\"/-------------------------------------/\")\n",
    "        print(\"Iteracion: \", i + 1)\n",
    "        print(\"SVM\")\n",
    "        print(\"...\")\n",
    "        SVM_FUN(sizeTest, X_train, X_test, y_train, y_test)\n",
    "        print(\"ARBOL DE DECISIÓN\")\n",
    "        print(\"...\")\n",
    "        ArbolDesicion(sizeTest, 3, X_train, X_test, y_train, y_test)\n",
    "        print(\"REGRESIÓN LOGISTICA\")\n",
    "        print(\"...\")\n",
    "        RegresionLogistica(sizeTest,  X_train, X_test, y_train, y_test)\n",
    "        \n",
    "    # Promedios de las metricas SVM\n",
    "    SVM[0] = SVM[0] / N     # Presición\n",
    "    SVM[1] = SVM[1] / N     # Recall\n",
    "    SVM[2] = SVM[2] / N     # F1 Score\n",
    "    \n",
    "    # Promedios de las metricas Arboles de decisión\n",
    "    ARBOL[0] = ARBOL[0] / N     # Presición\n",
    "    ARBOL[1] = ARBOL[1] / N     # Recall\n",
    "    ARBOL[2] = ARBOL[2] / N     # F1 Score\n",
    "    \n",
    "    # Promedios de las metricas Regresión Logistica\n",
    "    REGRESION[0] = REGRESION[0] / N     # Presición\n",
    "    REGRESION[1] = REGRESION[1] / N     # Recall\n",
    "    REGRESION[2] = REGRESION[2] / N     # F1 Score\n",
    "    \n",
    "    print(\"/--------PROMEDIOS----------/\")\n",
    "    print(\"* Resultados de promedios SVM\")\n",
    "    print(\"    Promedio Recall después de {0} iteraciones: {1}\".format(N,SVM[0]))\n",
    "    print(\"    Promedio Presición después de {0} iteraciones: {1}\".format(N,SVM[1]))\n",
    "    print(\"    Promedio F1 después de {0} iteraciones: {1}\".format(N,SVM[2]))\n",
    "    print(\"* Resultados de promedios ARBOLES DE DECISIÓN\")\n",
    "    print(\"    Promedio Recall después de {0} iteraciones: {1}\".format(N,ARBOL[0]))\n",
    "    print(\"    Promedio Presición después de {0} iteraciones: {1}\".format(N,ARBOL[1]))\n",
    "    print(\"    Promedio F1 después de {0} iteraciones: {1}\".format(N,ARBOL[2]))\n",
    "    print(\"* Resultados de promedios REGRESIÓN LOGISTICA\")\n",
    "    print(\"    Promedio Recall después de {0} iteraciones: {1}\".format(N,REGRESION[0]))\n",
    "    print(\"    Promedio Presición después de {0} iteraciones: {1}\".format(N,REGRESION[1]))\n",
    "    print(\"    Promedio F1 después de {0} iteraciones: {1}\".format(N,REGRESION[2]))\n",
    "    \n",
    "main(5, 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Actividades a realizar a partir de este script básico: </h1>\n",
    "1.  Implementar el método holdout para obtener unas métricas de desempeño más confiables. Hacer 5 iteraciones  de las etapas de: partición de los datos - entrenamiento - prueba - calculo de metricas. No olvidar liberar la semilla del generador de números aleatorios.\n",
    "<br></br>\n",
    "2.  Adicionar dos métodos para poder comparar su desempeño, los métodos a adicionar son: árbol de decisiones y clasificacador por regresión logística.\n",
    "<br></br>\n",
    "3.  Mostrar los resultados comparativos gráficamente, incluyendo la visualización de las curvas ROC por cada método y el valor del área bajo la curva."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
